import numpy as np
import matplotlib.pyplot as plt
import matplotlib.animation as animation
from scipy.io import wavfile
from scipy.fft import fft, fftfreq
from map_notes import get_closest_note


# Define constants
PATH = "media/Chords/E7.wav"  # Path to .wav file from project root
BIN_SIZE = 2.00                  # Size of bin in seconds
BIN_STEP = 0.01                  # Distance between successive bins in seconds
FREQ_LOWER_BOUND = 0             # Exclusive lower bound on the frequency 
FREQ_UPPER_BOUND = 1200          # Exclusive upper bound on the frequency


# Loads data from the .wav file, selects left channel (if necessary), and normalizes  
# - 'path' should be a file path (string) relative to the project root
# - returns 'rate' (the sample rate), and 'data' (the time series of amplitudes)
def load_data(path):

    # Load .wav file as specified in PATH
    rate, data = wavfile.read(PATH)

    # If data has multiple channels, take the left channel
    if data.ndim > 1:
        data = data[:, 0]

    # Normalize the data to a 32-bit float between -1 and 1
    data = np.float32(data / np.max(np.abs(data)))
    return rate, data


# Take the FFT of a single bin and return the relevant frequencies.
# - 'rate' is the sample rate (an integer).
# - 'subset' should be a 1-dimensional vector from 'data'.
# - returns an Cx2 array of (frequency, amplitude) paris.
def transform_subset(rate, subset):

    # Get all (frequency, amplitude) pairs using the FFT
    xf = fftfreq(len(subset), 1 / rate)
    yf = np.abs(fft(subset))

    # Filter the results on frequencies between 0 and 1200
    idx = np.where((xf > FREQ_LOWER_BOUND) & (xf < FREQ_UPPER_BOUND))
    return np.column_stack((xf[idx], yf[idx]))


# Bin and transform the data:
# - 'rate' is the sample rate (an integer).
# - 'data' should be a 1-dimensional vector.
# - returns an AxCx2 array of FFT results for each bin.
def transform_data(rate, data):

    # Transform BIN_SIZE and BIN_STEP into units of indices using the sample rate
    size = np.int32(BIN_SIZE * rate)
    step = np.int32(BIN_STEP * rate)

    # Get the bins as an AxB array where each 1D sub-array is a subset of the data
    bins = np.lib.stride_tricks.sliding_window_view(data, size)[::step]

    # Run the FFT on each subarray using transform_subset (AxB -> AxCx2)
    transform_bin = lambda x : transform_subset(rate, x)
    return np.apply_along_axis(transform_bin, axis = 1, arr = bins)


# Extract the n loudest notes at each time step
def extract_loudest_notes(fft_series, n):

    # Get the indices sorted by amplitude for each time step
    sorted_indices = np.apply_along_axis(
        lambda x : np.argsort(-x),
        axis = 1,
        arr = fft_series[:, :, 1]
    )

    # Get the frequencies sorted by amplitude for each time step
    rows = np.arange(len(fft_series))[:, None]
    sorted_frequencies = fft_series[rows, sorted_indices, 0]

    # Convert each of the sorted frequencies to notes
    sorted_notes = np.vectorize(get_closest_note)(sorted_frequencies)
    sorted_notes = [[str(x) for x in sub] for sub in sorted_notes]

    # Get the first three unique notes in each sublist
    return [list(dict.fromkeys(x))[:n] for x in sorted_notes]


# Animates the results of the binned FFT
# - 'fft_series' should be an AxCx2 array of FFT results generated by 'transform_data'.
# - 'note_series' is an AxN array of loudest notes generated by 'extract_loudest_notes'.
# - returns a matplotlib animation showing the FFT results over time.
def animate_results(fft_series, note_series):

    # Compute the animation interval in ms using the bin step
    interval = BIN_STEP * 1000

    # Initialize an empty plot
    fig, ax = plt.subplots()
    line, = ax.plot([], [], color = "blue")

    # Overlay time text in top right
    time_text = ax.text(
        0.95,
        0.95,
        "",
        transform = ax.transAxes,
        ha = "right",
        va = "top",
        fontsize = 12
    )

    # Overlay peak text in top left
    peak_text = ax.text(
        0.05,
        0.95,
        "",
        transform = ax.transAxes,
        ha = "left",
        va = "top",
        fontsize = 12
    )

    # Set limits based on the extent of the data
    ax.set_xlim(FREQ_LOWER_BOUND, FREQ_UPPER_BOUND)
    ax.set_ylim(fft_series[...,1].min(), fft_series[...,1].max())

    # Initialize the plot
    def init():
        line.set_data([], [])
        time_text.set_text("")
        peak_text.set_text("")
        return line, time_text

    def update(frame):
        coords = fft_series[frame]  
        notes = note_series[frame]
        line.set_data(coords[:, 0], coords[:, 1])
        time_text.set_text(f"Time: {frame * BIN_STEP:.2f}s")
        peak_text.set_text(f"Peaks: {notes}")
        return line, time_text, peak_text

    ani = animation.FuncAnimation(
        fig,
        update,
        frames = fft_series.shape[0],
        init_func = init,
        blit = True,
        interval = interval,
        repeat = False
    )

    # Configure FFMpegWriter with audio as a second input
    writer = animation.FFMpegWriter(
        fps = 1000 // interval,
        codec = "h264",
        bitrate = None,  
        extra_args = [
            # Add audio as second input
            "-i", PATH,
            # Ensure widely-compatible color format
            "-pix_fmt", "yuv420p",
            # Map streams explicitly: video from pipe (0), audio from file (1)
            "-map", "0:v:0",
            "-map", "1:a:0",
            # Encode audio as AAC (common choice for MP4)
            "-c:a", "aac",
            "-b:a", "192k",
            # Stop when the shorter of the two streams ends
            "-shortest",
            # Fast-start for web playback (move moov atom to front)
            "-movflags", "+faststart"
        ]
    )

    # Save
    ani.save("plots/bin-animation.mp4", writer = writer, dpi = 150)
    plt.close(fig)


rate, data = load_data(PATH)
fft_series = transform_data(rate, data)
note_series = extract_loudest_notes(fft_series, 5)
animate_results(fft_series, note_series)
